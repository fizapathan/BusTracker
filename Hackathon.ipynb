{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snce the dataset for people entering and leaving a bus could not be found,\n",
    "# we have implemented it for counting the number of people entering and leaving a\n",
    "# department store. This can be easily extended to busses.\n",
    "# USAGE\n",
    "# To read and write back out to video:\n",
    "# python passenger_counter.py --prototxt mobilenet_ssd/MobileNetSSD_deploy.prototxt \\\n",
    "#--model mobilenet_ssd/MobileNetSSD_deploy.caffemodel --input videos/example_01.mp4 \\\n",
    "#--output output/output_01.avi\n",
    "#\n",
    "# To read from webcam and write back out to disk:\n",
    "# python passenger_counter.py --prototxt mobilenet_ssd/MobileNetSSD_deploy.prototxt \\\n",
    "#--model mobilenet_ssd/MobileNetSSD_deploy.caffemodel \\\n",
    "#--output output/webcam_output.avi\n",
    "\n",
    "# import the necessary packages\n",
    "from pyimagesearch.centroidtracker import CentroidTracker\n",
    "from pyimagesearch.trackableobject import TrackableObject\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-p\", \"--prototxt\", required=True,\n",
    "    help=\"path to Caffe 'deploy' prototxt file\")\n",
    "ap.add_argument(\"-m\", \"--model\", required=True,\n",
    "    help=\"path to Caffe pre-trained model\")\n",
    "ap.add_argument(\"-i\", \"--input\", type=str,\n",
    "    help=\"path to optional input video file\")\n",
    "ap.add_argument(\"-o\", \"--output\", type=str,\n",
    "    help=\"path to optional output video file\")\n",
    "ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.4,\n",
    "    help=\"minimum probability to filter weak detections\")\n",
    "ap.add_argument(\"-s\", \"--skip-frames\", type=int, default=30,\n",
    "    help=\"# of skip frames between detections\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# initialize the list of class labels MobileNet SSD was trained to\n",
    "# detect\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "    \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "    \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "    \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "# load our serialized model from disk\n",
    "print(\"[INFO] loading model...\")\n",
    "net = cv2.dnn.readNetFromCaffe(args[\"prototxt\"], args[\"model\"])\n",
    "\n",
    "# if a video path was not supplied, grab a reference to the webcam\n",
    "if not args.get(\"input\", False):\n",
    "    print(\"[INFO] starting video stream...\")\n",
    "    vs = VideoStream(src=0).start()\n",
    "    time.sleep(2.0)\n",
    "\n",
    "# otherwise, grab a reference to the video file\n",
    "else:\n",
    "    print(\"[INFO] opening video file...\")\n",
    "    vs = cv2.VideoCapture(args[\"input\"])\n",
    "\n",
    "# initialize the video writer (we'll instantiate later if need be)\n",
    "writer = None\n",
    "\n",
    "# initialize the frame dimensions (to be set just after reading \n",
    "# from the first frame of the video)\n",
    "W = None\n",
    "H = None\n",
    "\n",
    "# instantiate  centroid tracker, then initialize a list to store\n",
    "# each of  dlib correlation trackers, followed by a dictionary to\n",
    "# map each unique object ID to a TrackableObject\n",
    "ct = CentroidTracker(maxDisappeared=40, maxDistance=50)\n",
    "trackers = []\n",
    "trackableObjects = {}\n",
    "\n",
    "# initialize the total number of frames processed thus far, along\n",
    "# with the total number of objects that have moved either up or down\n",
    "totalFrames = 0\n",
    "totalDown = 0\n",
    "totalUp = 0\n",
    "\n",
    "# start the frames per second throughput estimator\n",
    "fps = FPS().start()\n",
    "\n",
    "# looping over frames from the video stream\n",
    "while True:\n",
    "    # grab the next frame and handle if read either from\n",
    "    # VideoCapture or VideoStream\n",
    "    frame = vs.read()\n",
    "    frame = frame[1] if args.get(\"input\", False) else frame\n",
    "\n",
    "    # if a video is being viewed and did not grab a frame then it means \n",
    "    # that the end of the video has been reached\n",
    "    if args[\"input\"] is not None and frame is None:\n",
    "        break\n",
    "\n",
    "    # resize the frame to have a maximum width of 500 pixels (the\n",
    "    # less the data, the faster it can be processed), then convert\n",
    "    # the frame from BGR to RGB for dlib\n",
    "    frame = imutils.resize(frame, width=500)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # if the frame dimensions are empty, set them\n",
    "    if W is None or H is None:\n",
    "        (H, W) = frame.shape[:2]\n",
    "\n",
    "    # if video is being written to disk, initialize\n",
    "    # the writer\n",
    "    if args[\"output\"] is not None and writer is None:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "        writer = cv2.VideoWriter(args[\"output\"], fourcc, 30,\n",
    "            (W, H), True)\n",
    "\n",
    "    # initialize the current status along with the list of bounding\n",
    "    # box rectangles returned by either (1) object detector or\n",
    "    # (2) the correlation trackers\n",
    "    status = \"Waiting\"\n",
    "    rects = []\n",
    "\n",
    "    # check to see if a more computationally expensive\n",
    "    # object detection method is to be run to aid the tracker\n",
    "    if totalFrames % args[\"skip_frames\"] == 0:\n",
    "        # set the status and initialize the new set of object trackers\n",
    "        status = \"Detecting\"\n",
    "        trackers = []\n",
    "    \n",
    "        # convert the frame to a blob and pass the blob through the\n",
    "        # network and obtain the detections\n",
    "        blob = cv2.dnn.blobFromImage(frame, 0.007843, (W, H), 127.5)\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "\n",
    "        # loop over the detections\n",
    "        for i in np.arange(0, detections.shape[2]):\n",
    "            # extract the confidence (i.e., probability) associated\n",
    "            # with the prediction\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "\n",
    "            # filter out weak detections by requiring a minimum\n",
    "            # confidence\n",
    "            if confidence > args[\"confidence\"]:\n",
    "                # extract the index of the class label from the\n",
    "                # detections list\n",
    "                idx = int(detections[0, 0, i, 1])\n",
    "\n",
    "                # if the class label is not a person, ignore it\n",
    "                if CLASSES[idx] != \"person\":\n",
    "                    continue\n",
    "\n",
    "                # compute the (x, y)-coordinates of the bounding box\n",
    "                # for the object\n",
    "                box = detections[0, 0, i, 3:7] * np.array([W, H, W, H])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "                # construct a dlib rectangle object from the bounding\n",
    "                # box coordinates and then start the dlib correlation\n",
    "                # tracker\n",
    "                tracker = dlib.correlation_tracker()\n",
    "                rect = dlib.rectangle(startX, startY, endX, endY)\n",
    "                tracker.start_track(rgb, rect)\n",
    "\n",
    "                # add the tracker to the list of trackers so that\n",
    "                #it can be utilized to skip the frames\n",
    "                trackers.append(tracker)\n",
    "\n",
    "    # otherwise, utilize the object trackers rather than\n",
    "    # object detectors to obtain a higher frame processing throughout\n",
    "    else:\n",
    "        # loop over the trackers\n",
    "        for tracker in trackers:\n",
    "            # set the status of the system to be 'tracking' rather\n",
    "            # than 'waiting' or 'detecting'\n",
    "            status = \"Tracking\"\n",
    "\n",
    "            # update the tracker and grab the updated position\n",
    "            tracker.update(rgb)\n",
    "            pos = tracker.get_position()\n",
    "\n",
    "            # unpack the position object\n",
    "            startX = int(pos.left())\n",
    "            startY = int(pos.top())\n",
    "            endX = int(pos.right())\n",
    "            endY = int(pos.bottom())\n",
    "\n",
    "            # add the bounding box coordinates to the rectangles list\n",
    "            rects.append((startX, startY, endX, endY))\n",
    "\n",
    "    # draw a horizontal line in the center of the frame -- once an\n",
    "    # object crosses this line which will determine whether they were\n",
    "    # moving 'up' or 'down'\n",
    "    cv2.line(frame, (0, H // 2), (W, H // 2), (0, 255, 255), 2)\n",
    "\n",
    "    # use the centroid tracker to associate the (1) old object\n",
    "    # centroids with (2) the newly computed object centroids\n",
    "    objects = ct.update(rects)\n",
    "\n",
    "    # loop over the tracked objects\n",
    "    for (objectID, centroid) in objects.items():\n",
    "        # check to see if a trackable object exists for the current\n",
    "        # object ID\n",
    "        to = trackableObjects.get(objectID, None)\n",
    "\n",
    "        # if there is no existing trackable object, create one\n",
    "        if to is None:\n",
    "            to = TrackableObject(objectID, centroid)\n",
    "\n",
    "        # otherwise, there is a trackable object so we can utilize it\n",
    "        # to determine direction\n",
    "        else:\n",
    "            # the difference between the y-coordinate of the current\n",
    "            # centroid and the mean of previous centroids will tell\n",
    "            # direction int which the object is moving (negative for\n",
    "            # 'up' and positive for 'down')\n",
    "            y = [c[1] for c in to.centroids]\n",
    "            direction = centroid[1] - np.mean(y)\n",
    "            to.centroids.append(centroid)\n",
    "\n",
    "            # check to see if the object has been counted or not\n",
    "            if not to.counted:\n",
    "                # if the direction is negative (indicating the object\n",
    "                # is moving up) AND the centroid is above the center\n",
    "                # line, count the object\n",
    "                if direction < 0 and centroid[1] < H // 2:\n",
    "                    totalUp += 1\n",
    "                    to.counted = True\n",
    "\n",
    "                # if the direction is positive (indicating the object\n",
    "                # is moving down) AND the centroid is below the\n",
    "                # center line, count the object\n",
    "                elif direction > 0 and centroid[1] > H // 2:\n",
    "                    totalDown += 1\n",
    "                    to.counted = True\n",
    "\n",
    "        # store the trackable object in the dictionary\n",
    "        trackableObjects[objectID] = to\n",
    "\n",
    "        # draw both the ID of the object and the centroid of the\n",
    "        # object on the output frame\n",
    "        text = \"ID {}\".format(objectID)\n",
    "        cv2.putText(frame, text, (centroid[0] - 10, centroid[1] - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        cv2.circle(frame, (centroid[0], centroid[1]), 4, (0, 255, 0), -1)\n",
    "\n",
    "    # construct a tuple of information that will be displayed on the\n",
    "    # frame\n",
    "    info = [\n",
    "        (\"Up\", totalUp),\n",
    "        (\"Down\", totalDown),\n",
    "        (\"Status\", status),\n",
    "    ]\n",
    "\n",
    "    # loop over the info tuples and draw them on the frame\n",
    "    for (i, (k, v)) in enumerate(info):\n",
    "        text = \"{}: {}\".format(k, v)\n",
    "        cv2.putText(frame, text, (10, H - ((i * 20) + 20)),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "    # check to see if frame is to be written to the disk\n",
    "    if writer is not None:\n",
    "        writer.write(frame)\n",
    "\n",
    "    # show the output frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "    # increment the total number of frames processed thus far and\n",
    "    # then update the FPS counter\n",
    "    totalFrames += 1\n",
    "    fps.update()\n",
    "\n",
    "# stop the timer and display FPS information\n",
    "fps.stop()\n",
    "print(\"[INFO] elapsed time: {:.2f}\".format(fps.elapsed()))\n",
    "print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "\n",
    "# check to see if the video writer pointer need to be released \n",
    "if writer is not None:\n",
    "    writer.release()\n",
    "\n",
    "# if video file is not used, stop the camera video stream\n",
    "if not args.get(\"input\", False):\n",
    "    vs.stop()\n",
    "\n",
    "# otherwise, release the video file pointer\n",
    "else:\n",
    "    vs.release()\n",
    "\n",
    "# close any open windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing thre request libraries\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#api-endpoint\n",
    "URL=\"https://transit.api.here.com/v3/stations/by_name.json\"\n",
    "#defining a PARAMS dict for the parameters to be sent to the API\n",
    "PARAMS= {\n",
    "   'center': '40.7510,-73.9916',\n",
    "   'name': 'union',\n",
    "   'app_id': 'wweb8wBbFVGuEezx93lQ',\n",
    "   'app_code': 'Ik0Ljhr6y0t0n5EOpaXOXw',\n",
    "   'max': '10',\n",
    "  'method': 'fuzzy',\n",
    "  'radius': '5000'\n",
    "}\n",
    "# sending get request and saving the response as response object\n",
    "r = requests.get(url = URL,params = PARAMS) \n",
    "#extracting data in json format\n",
    "data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 2, 5, 7, 1, 6, 3]\n"
     ]
    }
   ],
   "source": [
    "#To sort the stations based on duration which is the length of \n",
    "#that leg of the travel\n",
    "Stn = data[\"Res\"][\"Stations\"][\"Stn\"]\n",
    "flag=0\n",
    "ans=dict()\n",
    "for i in range(len(Stn)):\n",
    "    s=\"\"\n",
    "    flag=0\n",
    "    for j in range(len(Stn[i][\"duration\"])):\n",
    "        mult=60*60\n",
    "        if(ord(Stn[i][\"duration\"][j])<=90 and ord(Stn[i][\"duration\"][j])>=65):\n",
    "            if(flag==1):\n",
    "                if(s!=\"\"):\n",
    "                    ans[i+1]=(int(s))*mult;\n",
    "                    mult/=60\n",
    "                s=\"\"\n",
    "            flag=1\n",
    "            continue\n",
    "        else:\n",
    "            s+=Stn[i][\"duration\"][j]\n",
    "print(sorted(ans,key=ans.__getitem__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To sort the stations based on the number of seats available.\n",
    "# For this the data of the number of passengers in the bus is\n",
    "# obtained real time using the passenger_counter algorithm.\n",
    "# For simplicity,here the total number of seats is assumed to \n",
    "# be the same for all busses at all stations and equal to TOTAL_SEATS\n",
    "# Let the number of people counted from the passenger_counter \n",
    "# algorithm be NO_OF_PASSENGERS[](obtained after extending the above\n",
    "# implementeed algorithm is extended to busses once the dataset can \n",
    "# be found)\n",
    "ans1 = dict()\n",
    "for i in range(len(Stn)):\n",
    "    ans1[i] = TOTAL_SEATS-NO_OF_PASSENGERS[i]\n",
    "print(list(reversed(sorted(ans1,key=ans1.__getitem__))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
